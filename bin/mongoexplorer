#!/usr/bin/env python
"""
Explore mongodb schemas
"""
# Stdlib
import argparse
import logging
import os
import subprocess
import sys
import time
# Third-party
from pymongo import MongoClient
# Local
from alsdata import core, report

_log = core.get_logger('mongoexplorer')


class ProgressMeterBase(object):
    def __init__(self, target=1, output=sys.stdout, prefix=''):
        self._tgt = target
        self._ts = None
        self._out = output
        self._pfx = prefix

    def start(self):
        pass

    def stop(self, p):
        pass

    def update(self, p):
        pass


class ProgressMeter(ProgressMeterBase):
    def start(self):
        self._ts = time.time()

    def stop(self, p):
        self.update(p)
        self._out.write('\n')

    def update(self, p):
        t = time.time()
        if p >= self._tgt:
            pct_done = 100
            eta = 0.0
        elif p <= 0:
            pct_done = 0
            eta = 0.0  # unknown!
        else:
            pct_done = (100 * p) // self._tgt
            elapsed = t - self._ts
            eta = (self._tgt / p - 1) * elapsed
        self._out.write('{} {:3d}% {:8d}/{:8d}   ETA: {:4.0f}s\r'.format(
            self._pfx, pct_done, p, self._tgt, eta))


def extract_schemas(coll, progress=False):
    sf = core.SchemaFactory()
    schemas = core.SchemaSet()

    if progress:
        ntot = coll.count()
        progmeter = ProgressMeter(ntot, prefix=coll.name)
        nincr = max([100, ntot//100])
    else:
        progmeter = ProgressMeterBase()
        nincr = 100

    n = 0
    progmeter.start()
    for doc in coll.find():
        if 0 == n % nincr:
            progmeter.update(n)
        schema = sf.process(doc)
        schemas.add(schema, doc['_id'])
        n += 1
    progmeter.stop(n)
    # print('{}'.format(n))
    return schemas


def print_reports(ofile, schemas, reporter, multi_pfx=None):
    i = 1
    if multi_pfx is not None:
        multi_meta = open('{}-meta.csv'.format(multi_pfx), 'w')
        multi_meta.write('count,file,ids\n')
    else:
        multi_meta = None
    for s, ids in schemas.items():
        count = len(ids)
        if len(ids) > 3:
            idlist = '{}, {}, .., {}'.format(
                ids[0], ids[1], ids[-1])
        else:
            idlist = ', '.join(map(str, ids))
        if multi_pfx is None:
            hdr = '-----------------------\n' \
                  '# Count = {:d}\n' \
                  '# ids = {}\n' \
                  '-----------------------\n'.format(count, idlist)
            ofile.write(hdr)
        else:
            fname = '{}_{:03d}_{}'.format(multi_pfx, i, count)
            reporter.set_output_file(open(fname, 'w'))
            multi_meta.write('{:d},"{}","{}"\n'.format(count, fname, idlist))
            i += 1
        reporter.write_schema(s)


def connect(host: str, port: int):
    if not host and not port:
        conn = MongoClient()
    elif host and not port:
        conn = MongoClient('mongodb://{}'.format(host))
    elif port and not host:
        conn = MongoClient('mongodb://:{:d}'.format(port))
    else:
        conn = MongoClient('mongodb://{}:{:d}'.format(host, port))
    return conn


def write_collection_header(db, coll, ofile):
    count = db.get_collection(coll).count()
    ofile.write('+=============================\n'
                '| Collection: {}\n'
                '| {:d} records\n'
                '+=============================\n'
                .format(coll, count))


def process_collection(db, coll, ofile, progress=None,
                       reporter_class=None, multi_pfx=None):
    coll = db.get_collection(coll)
    found = extract_schemas(coll, progress=progress)
    reporter = reporter_class(ofile, db.name, coll)
    print_reports(ofile, found, reporter, multi_pfx=multi_pfx)


def diff_all_files(path, prefix):
    prefix += '_'
    files = sorted(filter(lambda s: s.startswith(prefix), os.listdir(path)))
    n = len(files)
    for i in range(n):
        for j in range(i + 1, n):
            f1, f2 = (os.path.join(path, f) for f in (files[i], files[j]))
            ofile_path = os.path.join(path, 'diff-{:03d}_{:03d}.json'.format(i, j))
            ofile = open(ofile_path, 'w')
            cmd = ['jsondiff', '-i4', f1, f2]
            _log.debug('Running command "{}" to file "{}"'
                       .format(cmd, ofile.name))
            p = subprocess.Popen(cmd, stdout=ofile)
            if p.wait() != 0:
                _log.error('Error running command. Abort.')
                return -1
    return 0


def main():
    p = argparse.ArgumentParser()
    p.add_argument('-c', '--df', dest='coll', default='test',
                   help='Target collection, default=test. Use "*" for ALL')
    p.add_argument('-d', '--db', dest='db', default='alsdata',
                   help='Target database, default=alsdata')
    p.add_argument('-D', '--diff', dest='diff', action='store_true',
                   help='Instead of extracting schemas, diff schemas in '
                        'directory given by -m/--multiple and with prefix '
                        'given by -o/--output')
    p.add_argument('-m', '--multiple', dest='multi', default=None,
                   metavar='DIR',
                   help='Create multiple files, one per schema and store '
                        'them in <DIR>/<OFILE>_<#>')
    p.add_argument('-f', '--format', dest='fmt', default='text',
                   help='Output format (text, json) default=text')
    p.add_argument('-o', '--output', dest='output', default='-',
                   metavar='OFILE',
                   help='Output file, default=stdout')
    p.add_argument('-p', '--port', dest='port', type=int, default=0)
    p.add_argument('-P', '--progress', dest='progress', action='store_true',
                   help='Show progress meter')
    p.add_argument('-s', '--server', dest='host', default=None)
    p.add_argument('-v', '--verbose', dest='vb', action='count', default=0,
                   help='More messages from the program')
    args = p.parse_args()
    #
    _root_logger = core.get_logger()
    vb = int(args.vb)
    if vb > 2:
        _log.setLevel(logging.DEBUG)
        _root_logger.setLevel(logging.DEBUG)
    elif vb > 1:
        _log.setLevel(logging.INFO)
        _root_logger.setLevel(logging.INFO)
    else:
        _log.setLevel(logging.WARN)
        _root_logger.setLevel(logging.WARN)
    #
    if args.diff:
        if not args.multi:
            p.error('-D/--diff option requires directory from -m/--multi')
        if args.output == '-':
            p.error('-D/--diff option requires output pattern from -o/--output')
        return diff_all_files(args.multi, args.output)
    #
    _log.info('Connecting to MongoDB at {}:{}'.format(args.host, args.port))
    conn = connect(args.host, args.port)
    db = conn.get_database(args.db)
    # multiple files
    if args.multi is not None:
        if args.output == '-':
            p.error('-m/--multi option requires -o/--output option to be '
                    'set (cannot generate multiple files to stdout)')
        multi_pfx = os.path.join(args.multi, args.output)
        ofile = None
    else:
        multi_pfx = None
        # output file
        if args.output == '-':
            ofile = sys.stdout
            _log.info('Writing output to stdout')
        else:
            ofile = open(args.output, 'w')
            _log.info('Writing output to file "{}"'.format(ofile.name))
    # reporter
    rfmt, rclass = args.fmt.lower(), None
    if rfmt == 'text':
        rclass = report.TextReport
    elif rfmt == 'json':
        rclass = report.JsonSchemaReport
    else:
        p.error('Format must be "json" or "text", got: {}'.format(rfmt))
    # run
    if args.coll == '*':
        _log.info('Processing all collections in DB "{}"'.format(args.db))
        for coll in db.collection_names():
            write_collection_header(db, coll, ofile)
            process_collection(db, coll, ofile, progress=args.progress,
                               reporter_class=rclass, multi_pfx=multi_pfx)
    else:
        _log.info('Processing collection "{}" in DB "{}"'.format(args.coll,
                                                                 args.db))
        process_collection(db, args.coll, ofile, progress=args.progress,
                           reporter_class=rclass, multi_pfx=multi_pfx)
    return 0


if __name__ == '__main__':
    sys.exit(main())

